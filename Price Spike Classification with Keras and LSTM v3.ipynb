{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Concatenate, concatenate, TimeDistributed, Flatten\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# features is a list of strings of feature names \n",
    "\n",
    "def build_model(features, data_length):\n",
    "    \n",
    "    inputs_list = [] \n",
    "    for feature_name in features:\n",
    "        inputs_list.append((Input(shape=(data_length,1), name=feature_name)))\n",
    "    \n",
    "    layers = [] \n",
    "    for i, input_name in enumerate(inputs_list): \n",
    "        layers.append(LSTM(32, return_sequences=True)(inputs_list[i]) )\n",
    "        \n",
    "    merged = concatenate(layers) \n",
    "    \n",
    "    #main_output = Dense(32, activation='relu')(output)\n",
    "    \n",
    "    #output = TimeDistributed(Dense(3, activation='softmax', name='IsSpike'))(output)\n",
    "    \n",
    "    hidden1 = TimeDistributed(Dense(16, activation='relu'))(merged)\n",
    "    \n",
    "    flattened = Flatten()(hidden1) \n",
    "    \n",
    "    output = Dense(3, activation='softmax', name='IsSpike')(flattened)\n",
    "    \n",
    "    \n",
    "    model = Model(\n",
    "        inputs = inputs_list,\n",
    "        outputs = [output]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    \n",
    "\n",
    "data_length = 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Shape\n",
    "\n",
    "* Price  ----------> LSTM --\\\n",
    "* Google Trends ---> LSTM ---> Dense Layer -> Softmax -> Output: Is Spike (1,0,-1) \n",
    "* Volume ----------> LSTM --/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Input: Price, Google Trends, and Volume for time t0-t9 (10 hours of data) \n",
    "* Output: Is Spike (1,0,-1) for t10 \n",
    "    * Using 10 hours (t0-t9) of Price, Google Trends, and Volume to predict the price movement at t11 (t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:32: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py:1768: RuntimeWarning: invalid value encountered in subtract\n",
      "  return a[slice1]-a[slice2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>BitstampTrend</th>\n",
       "      <th>CoinbaseTrend</th>\n",
       "      <th>BubbleTrend</th>\n",
       "      <th>CryptocurrencyTrend</th>\n",
       "      <th>HashingTrend</th>\n",
       "      <th>BlockchainTrend</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.471970</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>0.526899</td>\n",
       "      <td>0.605058</td>\n",
       "      <td>0.535584</td>\n",
       "      <td>0.527141</td>\n",
       "      <td>0.333716</td>\n",
       "      <td>0.576911</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463316</td>\n",
       "      <td>0.439996</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.524515</td>\n",
       "      <td>0.551960</td>\n",
       "      <td>0.512201</td>\n",
       "      <td>0.501026</td>\n",
       "      <td>0.395838</td>\n",
       "      <td>0.520447</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725079</td>\n",
       "      <td>0.529463</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.503101</td>\n",
       "      <td>0.578359</td>\n",
       "      <td>0.574125</td>\n",
       "      <td>0.500021</td>\n",
       "      <td>0.328380</td>\n",
       "      <td>0.515816</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210661</td>\n",
       "      <td>0.416611</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.481687</td>\n",
       "      <td>0.550792</td>\n",
       "      <td>0.535584</td>\n",
       "      <td>0.490725</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.545998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.594148</td>\n",
       "      <td>0.445509</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.503101</td>\n",
       "      <td>0.610758</td>\n",
       "      <td>0.535584</td>\n",
       "      <td>0.652792</td>\n",
       "      <td>0.284584</td>\n",
       "      <td>0.438642</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Volume_BTC  Bitcoin_Adj     Close  Price_lagged  BitstampTrend  \\\n",
       "1    0.776791     0.471970  0.484557      0.484557       0.526899   \n",
       "2    0.463316     0.439996  0.538331      0.538331       0.524515   \n",
       "3    0.725079     0.529463  0.520715      0.520715       0.503101   \n",
       "4    0.210661     0.416611  0.566098      0.566098       0.481687   \n",
       "5    0.594148     0.445509  0.568881      0.568881       0.503101   \n",
       "\n",
       "   CoinbaseTrend  BubbleTrend  CryptocurrencyTrend  HashingTrend  \\\n",
       "1       0.605058     0.535584             0.527141      0.333716   \n",
       "2       0.551960     0.512201             0.501026      0.395838   \n",
       "3       0.578359     0.574125             0.500021      0.328380   \n",
       "4       0.550792     0.535584             0.490725      0.401071   \n",
       "5       0.610758     0.535584             0.652792      0.284584   \n",
       "\n",
       "   BlockchainTrend  Is Spike  \n",
       "1         0.576911       1.0  \n",
       "2         0.520447       1.0  \n",
       "3         0.515816      -1.0  \n",
       "4         0.545998       0.0  \n",
       "5         0.438642      -1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>BitstampTrend</th>\n",
       "      <th>CoinbaseTrend</th>\n",
       "      <th>BubbleTrend</th>\n",
       "      <th>CryptocurrencyTrend</th>\n",
       "      <th>HashingTrend</th>\n",
       "      <th>BlockchainTrend</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30197</th>\n",
       "      <td>0.511200</td>\n",
       "      <td>0.435052</td>\n",
       "      <td>0.528579</td>\n",
       "      <td>0.528579</td>\n",
       "      <td>0.498689</td>\n",
       "      <td>0.527715</td>\n",
       "      <td>0.473545</td>\n",
       "      <td>0.509784</td>\n",
       "      <td>0.371092</td>\n",
       "      <td>0.526187</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30198</th>\n",
       "      <td>0.478128</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.560737</td>\n",
       "      <td>0.560737</td>\n",
       "      <td>0.498596</td>\n",
       "      <td>0.554062</td>\n",
       "      <td>0.519161</td>\n",
       "      <td>0.518383</td>\n",
       "      <td>0.375046</td>\n",
       "      <td>0.525074</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30199</th>\n",
       "      <td>0.496631</td>\n",
       "      <td>0.427146</td>\n",
       "      <td>0.526134</td>\n",
       "      <td>0.526134</td>\n",
       "      <td>0.451915</td>\n",
       "      <td>0.552787</td>\n",
       "      <td>0.483831</td>\n",
       "      <td>0.518284</td>\n",
       "      <td>0.261137</td>\n",
       "      <td>0.524087</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30200</th>\n",
       "      <td>0.613268</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.516569</td>\n",
       "      <td>0.516569</td>\n",
       "      <td>0.401379</td>\n",
       "      <td>0.572967</td>\n",
       "      <td>0.517432</td>\n",
       "      <td>0.509883</td>\n",
       "      <td>0.379883</td>\n",
       "      <td>0.473249</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30201</th>\n",
       "      <td>0.443013</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.582366</td>\n",
       "      <td>0.582366</td>\n",
       "      <td>0.493590</td>\n",
       "      <td>0.599583</td>\n",
       "      <td>0.487998</td>\n",
       "      <td>0.514084</td>\n",
       "      <td>0.282666</td>\n",
       "      <td>0.536255</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume_BTC  Bitcoin_Adj     Close  Price_lagged  BitstampTrend  \\\n",
       "30197    0.511200     0.435052  0.528579      0.528579       0.498689   \n",
       "30198    0.478128     0.426471  0.560737      0.560737       0.498596   \n",
       "30199    0.496631     0.427146  0.526134      0.526134       0.451915   \n",
       "30200    0.613268     0.453625  0.516569      0.516569       0.401379   \n",
       "30201    0.443013     0.453625  0.582366      0.582366       0.493590   \n",
       "\n",
       "       CoinbaseTrend  BubbleTrend  CryptocurrencyTrend  HashingTrend  \\\n",
       "30197       0.527715     0.473545             0.509784      0.371092   \n",
       "30198       0.554062     0.519161             0.518383      0.375046   \n",
       "30199       0.552787     0.483831             0.518284      0.261137   \n",
       "30200       0.572967     0.517432             0.509883      0.379883   \n",
       "30201       0.599583     0.487998             0.514084      0.282666   \n",
       "\n",
       "       BlockchainTrend  Is Spike  \n",
       "30197         0.526187      -1.0  \n",
       "30198         0.525074      -1.0  \n",
       "30199         0.524087       1.0  \n",
       "30200         0.473249      -1.0  \n",
       "30201         0.536255       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "master_df = pd.read_csv('C:/Users/Shoya/surf/data/master_df_v3.csv', encoding='latin1')\n",
    "df = master_df[['Timestamp', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Date(UTC)', 'Bitcoin (Adj.Overlap)', \n",
    "               'Close Price % Change', 'Close Price % Change (Abs)', 'Is Spike']]\n",
    "\n",
    "\n",
    "trends_df = pd.read_csv('C:/Users/Shoya/surf/data/Adj_Google_Trends_for_Mult_Keywords.csv', encoding='latin1') \n",
    "trends_cols = [\"BitstampTrend\", \"CoinbaseTrend\", \"EthereumTrend\", \"BubbleTrend\", \"CryptocurrencyTrend\", \n",
    "               \"HashingTrend\", \"BlockchainTrend\" ]\n",
    "\n",
    "\n",
    "# lag inputs depending on data_length \n",
    "df['Price_lagged'] = df['Close']#.shift(data_length)\n",
    "df['Volume_BTC'] = df['Volume_(BTC)']#.shift(data_length)\n",
    "df['Bitcoin_Adj'] = df['Bitcoin (Adj.Overlap)']#.shift(data_length)\n",
    "\n",
    "df[trends_cols] = trends_df[trends_cols]\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "#cols = ['Volume_BTC','Bitcoin_Adj', 'Close', 'Price_lagged']\n",
    "cols = [\n",
    " 'Volume_BTC','Bitcoin_Adj', 'Close', 'Price_lagged',\n",
    " \"BitstampTrend\", \"CoinbaseTrend\", \"BubbleTrend\", \"CryptocurrencyTrend\", \n",
    "    \"HashingTrend\", \"BlockchainTrend\"    \n",
    "]\n",
    "\n",
    "\n",
    "# Stationalize Data by taking log differences\n",
    "data_array = np.diff(np.log(df[cols]), axis=0)\n",
    "df_2 = pd.DataFrame(data_array, columns=cols)\n",
    "df_scaled = df_2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# Min-Max Scale \n",
    "\n",
    "scalers = {}\n",
    "datas = [] \n",
    "\n",
    "#df_scaled = pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Fix below - I am scaling the whole data set together, when I should scale the train and test datasets separately\n",
    "############################################################\n",
    "\n",
    "for i in range(len(cols)): \n",
    "    scalers[cols[i]] = MinMaxScaler()\n",
    "    #print('data', data_array[:,i])\n",
    "    \n",
    "    col_data = data_array[:,i]\n",
    "    \n",
    "    col_data = pd.Series(col_data).replace([np.inf, -np.inf], np.nan).dropna().values\n",
    "    \n",
    "    col_data = np.reshape(col_data, (len(col_data), 1))\n",
    "    \n",
    "    data = scalers[cols[i]].fit_transform( col_data )\n",
    "    #print('scaled', data)\n",
    "    data = np.reshape(data, (1, len(data)))\n",
    "    df_scaled[cols[i]] = pd.Series(data[0])\n",
    "\n",
    "df_scaled['Is Spike'] = df['Is Spike']\n",
    "df_scaled.dropna(inplace=True)\n",
    "display(df_scaled.head())\n",
    "display(df_scaled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# split and reshape data to feed into RNN\n",
    "\n",
    "# for some reason, the more elegant dict approach on v2 notebook doesn't work so I will do this longer version\n",
    "\n",
    "X_volume = df_scaled['Volume_BTC'].values\n",
    "X_trends = df_scaled['Bitcoin_Adj'].values\n",
    "X_lagged_price = df_scaled['Price_lagged'].values\n",
    "X_trends_coinbase = df_scaled[\"CoinbaseTrend\"].values\n",
    "X_trends_blockchain = df_scaled[\"BlockchainTrend\"].values\n",
    "X_trends_bubble = df_scaled[\"BubbleTrend\"].values\n",
    "\n",
    "Y_is_spike = df_scaled['Is Spike'].values \n",
    "\n",
    "# train_size = int(len(X_volume) * 0.80)\n",
    "# train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "test_size_index = int(len(X_volume)/data_length)*data_length\n",
    "\n",
    "train_size = int(len(X_volume) * 0.80)\n",
    "train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "X_train_volume = []\n",
    "X_test_volume = [] \n",
    "X_train_trends = []\n",
    "X_test_trends = []\n",
    "X_train_trends_coinbase = [] \n",
    "X_test_trends_coinbase = [] \n",
    "X_train_trends_blockchain = []\n",
    "X_test_trends_blockchain = []\n",
    "X_train_trends_bubble = []\n",
    "X_test_trends_bubble = []\n",
    "X_train_lagged_price = []\n",
    "X_test_lagged_price = []\n",
    "Y_train_is_spike = [] \n",
    "Y_test_is_spike = [] \n",
    "\n",
    "\n",
    "for i in range(train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = []\n",
    "    price_temp = []\n",
    "    trends_coinbase_temp = [] \n",
    "    trends_blockchain_temp = []\n",
    "    trends_bubble_temp = []\n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[i+j])\n",
    "        trends_temp.append(X_trends[i+j])\n",
    "        price_temp.append(X_lagged_price[i+j])\n",
    "        trends_coinbase_temp.append(X_trends_coinbase[i+j])\n",
    "        trends_blockchain_temp.append(X_trends_blockchain[i+j])\n",
    "        trends_bubble_temp.append(X_trends_bubble[i+j])\n",
    "    X_train_volume.append(vol_temp)\n",
    "    X_train_trends.append(trends_temp)\n",
    "    X_train_lagged_price.append(price_temp)\n",
    "    X_train_trends_coinbase.append(trends_coinbase_temp)\n",
    "    X_train_trends_blockchain.append(trends_blockchain_temp)\n",
    "    X_train_trends_bubble.append(trends_bubble_temp)\n",
    "    \n",
    "    Y_train_is_spike.append(Y_is_spike[i+data_length])\n",
    "    \n",
    "for i in range(test_size_index-train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = [] \n",
    "    price_temp = [] \n",
    "    trends_coinbase_temp = [] \n",
    "    trends_blockchain_temp = []\n",
    "    trends_bubble_temp = []\n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[train_size+i+j])\n",
    "        trends_temp.append(X_trends[train_size+i+j])\n",
    "        price_temp.append(X_lagged_price[train_size+i+j])\n",
    "        trends_coinbase_temp.append(X_trends_coinbase[train_size+i+j])\n",
    "        trends_blockchain_temp.append(X_trends_blockchain[train_size+i+j])\n",
    "        trends_bubble_temp.append(X_trends_bubble[train_size+i+j])\n",
    "    X_test_volume.append(vol_temp)\n",
    "    X_test_trends.append(trends_temp)\n",
    "    X_test_lagged_price.append(price_temp)\n",
    "    X_test_trends_coinbase.append(trends_coinbase_temp)\n",
    "    X_test_trends_blockchain.append(trends_blockchain_temp)\n",
    "    X_test_trends_bubble.append(trends_bubble_temp)\n",
    "    \n",
    "    Y_test_is_spike.append(Y_is_spike[train_size+i+data_length])\n",
    "    \n",
    "X_train_volume = np.array(X_train_volume)\n",
    "X_test_volume =  np.array(X_test_volume)\n",
    "X_train_trends = np.array(X_train_trends)\n",
    "X_test_trends = np.array(X_test_trends)\n",
    "X_train_trends_coinbase = np.array(X_train_trends_coinbase)\n",
    "X_test_trends_coinbase = np.array(X_test_trends_coinbase)\n",
    "X_train_lagged_price = np.array(X_train_lagged_price)\n",
    "X_test_lagged_price = np.array(X_test_lagged_price)\n",
    "X_train_trends_blockchain = np.array(X_train_trends_blockchain)\n",
    "X_test_trends_blockchain = np.array(X_test_trends_blockchain)\n",
    "X_train_trends_bubble = np.array(X_train_trends_bubble)\n",
    "X_test_trends_bubble = np.array(X_test_trends_bubble)\n",
    "Y_train_is_spike =  np.array(Y_train_is_spike)\n",
    "Y_test_is_spike = np.array(Y_test_is_spike)\n",
    "    \n",
    "    \n",
    "Y_train_is_spike_onehot = to_categorical(Y_train_is_spike, num_classes=3)\n",
    "Y_test_is_spike_onehot = to_categorical(Y_test_is_spike,num_classes=3)\n",
    "\n",
    "\n",
    "\n",
    "X_train_volume = np.reshape(X_train_volume, (X_train_volume.shape[0],data_length,1) ) \n",
    "X_train_trends = np.reshape(X_train_trends, (X_train_trends.shape[0],data_length,1) ) \n",
    "X_train_trends_coinbase = np.reshape(X_train_trends_coinbase, (X_train_trends_coinbase.shape[0],data_length,1) ) \n",
    "X_train_lagged_price = np.reshape(X_train_lagged_price, (X_train_lagged_price.shape[0], data_length, 1))\n",
    "X_train_trends_blockchain = np.reshape(X_train_trends_blockchain, (X_train_trends_blockchain.shape[0],data_length,1) )\n",
    "X_train_trends_bubble = np.reshape(X_train_trends_bubble, (X_train_trends_bubble.shape[0],data_length,1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575119</td>\n",
       "      <td>0.557883</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558755</td>\n",
       "      <td>0.541072</td>\n",
       "      <td>0.539979</td>\n",
       "      <td>0.539335</td>\n",
       "      <td>0.548901</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>0.539638</td>\n",
       "      <td>0.536557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557883</td>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541072</td>\n",
       "      <td>0.539979</td>\n",
       "      <td>0.539335</td>\n",
       "      <td>0.548901</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>0.539638</td>\n",
       "      <td>0.536557</td>\n",
       "      <td>0.554422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530973</td>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.565229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539979</td>\n",
       "      <td>0.539335</td>\n",
       "      <td>0.548901</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>0.539638</td>\n",
       "      <td>0.536557</td>\n",
       "      <td>0.554422</td>\n",
       "      <td>0.547941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519940</td>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.565229</td>\n",
       "      <td>0.575437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539335</td>\n",
       "      <td>0.548901</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>0.539638</td>\n",
       "      <td>0.536557</td>\n",
       "      <td>0.554422</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.539293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540369</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>0.537179</td>\n",
       "      <td>0.609281</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.524064</td>\n",
       "      <td>0.565229</td>\n",
       "      <td>0.575437</td>\n",
       "      <td>0.524171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548901</td>\n",
       "      <td>0.538739</td>\n",
       "      <td>0.542131</td>\n",
       "      <td>0.549157</td>\n",
       "      <td>0.539638</td>\n",
       "      <td>0.536557</td>\n",
       "      <td>0.554422</td>\n",
       "      <td>0.547941</td>\n",
       "      <td>0.539293</td>\n",
       "      <td>0.547441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.575119  0.557883  0.530973  0.519940  0.540369  0.552200  0.541641   \n",
       "1  0.557883  0.530973  0.519940  0.540369  0.552200  0.541641  0.537179   \n",
       "2  0.530973  0.519940  0.540369  0.552200  0.541641  0.537179  0.609281   \n",
       "3  0.519940  0.540369  0.552200  0.541641  0.537179  0.609281  0.544154   \n",
       "4  0.540369  0.552200  0.541641  0.537179  0.609281  0.544154  0.524064   \n",
       "\n",
       "       7         8         9       ...         5990      5991      5992  \\\n",
       "0  0.537179  0.609281  0.544154    ...     0.558755  0.541072  0.539979   \n",
       "1  0.609281  0.544154  0.524064    ...     0.541072  0.539979  0.539335   \n",
       "2  0.544154  0.524064  0.565229    ...     0.539979  0.539335  0.548901   \n",
       "3  0.524064  0.565229  0.575437    ...     0.539335  0.548901  0.538739   \n",
       "4  0.565229  0.575437  0.524171    ...     0.548901  0.538739  0.542131   \n",
       "\n",
       "       5993      5994      5995      5996      5997      5998      5999  \n",
       "0  0.539335  0.548901  0.538739  0.542131  0.549157  0.539638  0.536557  \n",
       "1  0.548901  0.538739  0.542131  0.549157  0.539638  0.536557  0.554422  \n",
       "2  0.538739  0.542131  0.549157  0.539638  0.536557  0.554422  0.547941  \n",
       "3  0.542131  0.549157  0.539638  0.536557  0.554422  0.547941  0.539293  \n",
       "4  0.549157  0.539638  0.536557  0.554422  0.547941  0.539293  0.547441  \n",
       "\n",
       "[5 rows x 6000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_check = pd.DataFrame(X_train_lagged_price[0])\n",
    "for i in range(1,len(X_train_lagged_price)):\n",
    "    df_train_check[i] = X_train_lagged_price[i]\n",
    "\n",
    "df_test_check = pd.DataFrame(X_test_lagged_price[0])\n",
    "\n",
    "for i in range(1,len(X_test_lagged_price)):\n",
    "    df_test_check[i] = X_test_lagged_price[i]\n",
    "\n",
    "df_train_check.head()    \n",
    "df_test_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(X_lagged_price))\n",
    "display(len(X_train_lagged_price))\n",
    "display(len(X_test_lagged_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24038</th>\n",
       "      <th>24039</th>\n",
       "      <th>24040</th>\n",
       "      <th>24041</th>\n",
       "      <th>24042</th>\n",
       "      <th>24043</th>\n",
       "      <th>24044</th>\n",
       "      <th>24045</th>\n",
       "      <th>24046</th>\n",
       "      <th>24047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.484557</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.523904</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578648</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.534130</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.624524</td>\n",
       "      <td>0.527643</td>\n",
       "      <td>0.619001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.523904</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489107</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.534130</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.624524</td>\n",
       "      <td>0.527643</td>\n",
       "      <td>0.619001</td>\n",
       "      <td>0.627446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.523904</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574141</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.534130</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.624524</td>\n",
       "      <td>0.527643</td>\n",
       "      <td>0.619001</td>\n",
       "      <td>0.627446</td>\n",
       "      <td>0.601662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.523904</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>0.514868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534550</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.534130</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.624524</td>\n",
       "      <td>0.527643</td>\n",
       "      <td>0.619001</td>\n",
       "      <td>0.627446</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>0.542777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.523904</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.533277</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>0.514868</td>\n",
       "      <td>0.531067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550966</td>\n",
       "      <td>0.534130</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.624524</td>\n",
       "      <td>0.527643</td>\n",
       "      <td>0.619001</td>\n",
       "      <td>0.627446</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>0.542777</td>\n",
       "      <td>0.326392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6      \\\n",
       "0  0.484557  0.538331  0.520715  0.566098  0.568881  0.523904  0.520334   \n",
       "1  0.538331  0.520715  0.566098  0.568881  0.523904  0.520334  0.533277   \n",
       "2  0.520715  0.566098  0.568881  0.523904  0.520334  0.533277  0.463739   \n",
       "3  0.566098  0.568881  0.523904  0.520334  0.533277  0.463739  0.545460   \n",
       "4  0.568881  0.523904  0.520334  0.533277  0.463739  0.545460  0.550962   \n",
       "\n",
       "      7         8         9        ...        24038     24039     24040  \\\n",
       "0  0.533277  0.463739  0.545460    ...     0.578648  0.489107  0.574141   \n",
       "1  0.463739  0.545460  0.550962    ...     0.489107  0.574141  0.534550   \n",
       "2  0.545460  0.550962  0.548729    ...     0.574141  0.534550  0.550966   \n",
       "3  0.550962  0.548729  0.514868    ...     0.534550  0.550966  0.534130   \n",
       "4  0.548729  0.514868  0.531067    ...     0.550966  0.534130  0.567577   \n",
       "\n",
       "      24041     24042     24043     24044     24045     24046     24047  \n",
       "0  0.534550  0.550966  0.534130  0.567577  0.624524  0.527643  0.619001  \n",
       "1  0.550966  0.534130  0.567577  0.624524  0.527643  0.619001  0.627446  \n",
       "2  0.534130  0.567577  0.624524  0.527643  0.619001  0.627446  0.601662  \n",
       "3  0.567577  0.624524  0.527643  0.619001  0.627446  0.601662  0.542777  \n",
       "4  0.624524  0.527643  0.619001  0.627446  0.601662  0.542777  0.326392  \n",
       "\n",
       "[5 rows x 24048 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train_check.head())\n",
    "\n",
    "writer = pd.ExcelWriter(\"checktrain.xlsx\",  engine='xlsxwriter', options={'remove_timezone': True})\n",
    "df_train_check.transpose().to_excel(writer)\n",
    "writer.save()\n",
    "\n",
    "writer2 = pd.ExcelWriter(\"checktest.xlsx\",  engine='xlsxwriter', options={'remove_timezone': True})\n",
    "df_test_check.transpose().to_excel(writer2)\n",
    "writer2.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_volume = np.reshape(X_test_volume, (X_test_volume.shape[0],data_length,1) ) \n",
    "X_test_trends = np.reshape(X_test_trends, (X_test_trends.shape[0],data_length,1) )  \n",
    "X_test_trends_coinbase = np.reshape(X_test_trends_coinbase, (X_test_trends_coinbase.shape[0],data_length,1) )  \n",
    "X_test_lagged_price = np.reshape(X_test_lagged_price, (X_test_lagged_price.shape[0],data_length,1))\n",
    "X_test_trends_blockchain = np.reshape(X_test_trends_blockchain, (X_test_trends_blockchain.shape[0],data_length,1) )\n",
    "X_test_trends_bubble = np.reshape(X_test_trends_bubble, (X_test_trends_bubble.shape[0],data_length,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22048 samples, validate on 6000 samples\n",
      "Epoch 1/100\n",
      "22048/22048 [==============================] - 78s - loss: 1.0672 - categorical_accuracy: 0.4575 - val_loss: 1.2144 - val_categorical_accuracy: 0.2457\n",
      "Epoch 2/100\n",
      "22048/22048 [==============================] - 75s - loss: 1.0663 - categorical_accuracy: 0.4580 - val_loss: 1.1855 - val_categorical_accuracy: 0.2457\n",
      "Epoch 3/100\n",
      "22048/22048 [==============================] - 75s - loss: 1.0665 - categorical_accuracy: 0.4580 - val_loss: 1.1705 - val_categorical_accuracy: 0.2457\n",
      "Epoch 4/100\n",
      "22048/22048 [==============================] - 67s - loss: 1.0663 - categorical_accuracy: 0.4580 - val_loss: 1.1539 - val_categorical_accuracy: 0.2457\n",
      "Epoch 5/100\n",
      "22048/22048 [==============================] - 54s - loss: 1.0661 - categorical_accuracy: 0.4580 - val_loss: 1.1882 - val_categorical_accuracy: 0.2457\n",
      "Epoch 6/100\n",
      "22048/22048 [==============================] - 55s - loss: 1.0663 - categorical_accuracy: 0.4580 - val_loss: 1.1996 - val_categorical_accuracy: 0.2457\n",
      "Epoch 7/100\n",
      "22048/22048 [==============================] - 51s - loss: 1.0655 - categorical_accuracy: 0.4580 - val_loss: 1.1710 - val_categorical_accuracy: 0.2457\n",
      "Epoch 8/100\n",
      "22048/22048 [==============================] - 56s - loss: 1.0659 - categorical_accuracy: 0.4580 - val_loss: 1.1895 - val_categorical_accuracy: 0.2457\n",
      "Epoch 9/100\n",
      "22048/22048 [==============================] - 52s - loss: 1.0658 - categorical_accuracy: 0.4580 - val_loss: 1.1940 - val_categorical_accuracy: 0.2457\n",
      "Epoch 10/100\n",
      "22048/22048 [==============================] - 52s - loss: 1.0653 - categorical_accuracy: 0.4580 - val_loss: 1.1652 - val_categorical_accuracy: 0.2457\n",
      "Epoch 11/100\n",
      "22048/22048 [==============================] - 52s - loss: 1.0646 - categorical_accuracy: 0.4580 - val_loss: 1.1758 - val_categorical_accuracy: 0.2457\n",
      "Epoch 12/100\n",
      "22048/22048 [==============================] - 52s - loss: 1.0635 - categorical_accuracy: 0.4580 - val_loss: 1.1559 - val_categorical_accuracy: 0.2457\n",
      "Epoch 13/100\n",
      "22048/22048 [==============================] - 52s - loss: 1.0572 - categorical_accuracy: 0.4604 - val_loss: 1.1445 - val_categorical_accuracy: 0.3078\n",
      "Epoch 14/100\n",
      "22048/22048 [==============================] - 53s - loss: 1.0345 - categorical_accuracy: 0.4845 - val_loss: 1.1304 - val_categorical_accuracy: 0.4255\n",
      "Epoch 15/100\n",
      "22048/22048 [==============================] - 53s - loss: 1.0088 - categorical_accuracy: 0.5075 - val_loss: 1.1171 - val_categorical_accuracy: 0.4285\n",
      "Epoch 16/100\n",
      "22048/22048 [==============================] - 57s - loss: 0.9982 - categorical_accuracy: 0.5186 - val_loss: 1.0498 - val_categorical_accuracy: 0.4523\n",
      "Epoch 17/100\n",
      "22048/22048 [==============================] - 56s - loss: 0.9891 - categorical_accuracy: 0.5265 - val_loss: 1.0435 - val_categorical_accuracy: 0.4595\n",
      "Epoch 18/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9842 - categorical_accuracy: 0.5292 - val_loss: 1.0437 - val_categorical_accuracy: 0.4723\n",
      "Epoch 19/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9790 - categorical_accuracy: 0.5332 - val_loss: 1.1033 - val_categorical_accuracy: 0.4673\n",
      "Epoch 20/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9736 - categorical_accuracy: 0.5384 - val_loss: 1.0570 - val_categorical_accuracy: 0.4815\n",
      "Epoch 21/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9677 - categorical_accuracy: 0.5422 - val_loss: 1.0836 - val_categorical_accuracy: 0.4713\n",
      "Epoch 22/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9618 - categorical_accuracy: 0.5435 - val_loss: 1.0619 - val_categorical_accuracy: 0.4708\n",
      "Epoch 23/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9564 - categorical_accuracy: 0.5503 - val_loss: 1.0231 - val_categorical_accuracy: 0.4887\n",
      "Epoch 24/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9514 - categorical_accuracy: 0.5528 - val_loss: 1.0216 - val_categorical_accuracy: 0.5023\n",
      "Epoch 25/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9473 - categorical_accuracy: 0.5544 - val_loss: 1.0035 - val_categorical_accuracy: 0.5043\n",
      "Epoch 26/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9424 - categorical_accuracy: 0.5574 - val_loss: 1.0316 - val_categorical_accuracy: 0.5013\n",
      "Epoch 27/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.9363 - categorical_accuracy: 0.5625 - val_loss: 1.0697 - val_categorical_accuracy: 0.4838\n",
      "Epoch 28/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.9293 - categorical_accuracy: 0.5632 - val_loss: 1.0699 - val_categorical_accuracy: 0.4595\n",
      "Epoch 29/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.9214 - categorical_accuracy: 0.5691 - val_loss: 1.0265 - val_categorical_accuracy: 0.5048\n",
      "Epoch 30/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.9104 - categorical_accuracy: 0.5781 - val_loss: 1.0379 - val_categorical_accuracy: 0.5100\n",
      "Epoch 31/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.9010 - categorical_accuracy: 0.5839 - val_loss: 1.0445 - val_categorical_accuracy: 0.5108\n",
      "Epoch 32/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8937 - categorical_accuracy: 0.5899 - val_loss: 1.0378 - val_categorical_accuracy: 0.5145\n",
      "Epoch 33/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8867 - categorical_accuracy: 0.5939 - val_loss: 1.0739 - val_categorical_accuracy: 0.5080\n",
      "Epoch 34/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8792 - categorical_accuracy: 0.5980 - val_loss: 1.1090 - val_categorical_accuracy: 0.5133\n",
      "Epoch 35/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8749 - categorical_accuracy: 0.6031 - val_loss: 1.1355 - val_categorical_accuracy: 0.5037\n",
      "Epoch 36/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8710 - categorical_accuracy: 0.6027 - val_loss: 1.2205 - val_categorical_accuracy: 0.4828\n",
      "Epoch 37/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8650 - categorical_accuracy: 0.6091 - val_loss: 1.1018 - val_categorical_accuracy: 0.4975\n",
      "Epoch 38/100\n",
      "22048/22048 [==============================] - 56s - loss: 0.8602 - categorical_accuracy: 0.6105 - val_loss: 1.0582 - val_categorical_accuracy: 0.5223\n",
      "Epoch 39/100\n",
      "22048/22048 [==============================] - 55s - loss: 0.8568 - categorical_accuracy: 0.6094 - val_loss: 1.0917 - val_categorical_accuracy: 0.5195\n",
      "Epoch 40/100\n",
      "22048/22048 [==============================] - 55s - loss: 0.8524 - categorical_accuracy: 0.6151 - val_loss: 1.0892 - val_categorical_accuracy: 0.5098\n",
      "Epoch 41/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8471 - categorical_accuracy: 0.6185 - val_loss: 1.1279 - val_categorical_accuracy: 0.5142\n",
      "Epoch 42/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8418 - categorical_accuracy: 0.6213 - val_loss: 1.0941 - val_categorical_accuracy: 0.5157\n",
      "Epoch 43/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8352 - categorical_accuracy: 0.6222 - val_loss: 1.1573 - val_categorical_accuracy: 0.5023\n",
      "Epoch 44/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8299 - categorical_accuracy: 0.6288 - val_loss: 1.1203 - val_categorical_accuracy: 0.5152\n",
      "Epoch 45/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8234 - categorical_accuracy: 0.6326 - val_loss: 1.1225 - val_categorical_accuracy: 0.5090\n",
      "Epoch 46/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8181 - categorical_accuracy: 0.6320 - val_loss: 1.0965 - val_categorical_accuracy: 0.5127\n",
      "Epoch 47/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8091 - categorical_accuracy: 0.6379 - val_loss: 1.1559 - val_categorical_accuracy: 0.5050\n",
      "Epoch 48/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.8046 - categorical_accuracy: 0.6372 - val_loss: 1.1612 - val_categorical_accuracy: 0.5025\n",
      "Epoch 49/100\n",
      "22048/22048 [==============================] - 55s - loss: 0.7978 - categorical_accuracy: 0.6411 - val_loss: 1.1445 - val_categorical_accuracy: 0.5133\n",
      "Epoch 50/100\n",
      "22048/22048 [==============================] - 55s - loss: 0.7915 - categorical_accuracy: 0.6411 - val_loss: 1.1003 - val_categorical_accuracy: 0.5120\n",
      "Epoch 51/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7866 - categorical_accuracy: 0.6436 - val_loss: 1.1138 - val_categorical_accuracy: 0.5015\n",
      "Epoch 52/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7814 - categorical_accuracy: 0.6475 - val_loss: 1.1026 - val_categorical_accuracy: 0.5103\n",
      "Epoch 53/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7767 - categorical_accuracy: 0.6495 - val_loss: 1.0878 - val_categorical_accuracy: 0.5110\n",
      "Epoch 54/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7714 - categorical_accuracy: 0.6519 - val_loss: 1.1158 - val_categorical_accuracy: 0.5050\n",
      "Epoch 55/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7675 - categorical_accuracy: 0.6499 - val_loss: 1.1211 - val_categorical_accuracy: 0.5100\n",
      "Epoch 56/100\n",
      "22048/22048 [==============================] - 51s - loss: 0.7628 - categorical_accuracy: 0.6534 - val_loss: 1.1198 - val_categorical_accuracy: 0.5073\n",
      "Epoch 57/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.7580 - categorical_accuracy: 0.6585 - val_loss: 1.0941 - val_categorical_accuracy: 0.5073\n",
      "Epoch 58/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.7524 - categorical_accuracy: 0.6619 - val_loss: 1.1666 - val_categorical_accuracy: 0.5038\n",
      "Epoch 59/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.7485 - categorical_accuracy: 0.6649 - val_loss: 1.1011 - val_categorical_accuracy: 0.5113\n",
      "Epoch 60/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.7437 - categorical_accuracy: 0.6666 - val_loss: 1.0974 - val_categorical_accuracy: 0.5288\n",
      "Epoch 61/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.7371 - categorical_accuracy: 0.6729 - val_loss: 1.1335 - val_categorical_accuracy: 0.5237\n",
      "Epoch 62/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.7304 - categorical_accuracy: 0.6736 - val_loss: 1.0852 - val_categorical_accuracy: 0.5245\n",
      "Epoch 63/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.7213 - categorical_accuracy: 0.6823 - val_loss: 1.1030 - val_categorical_accuracy: 0.5300\n",
      "Epoch 64/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6994 - categorical_accuracy: 0.7003 - val_loss: 1.1772 - val_categorical_accuracy: 0.5535\n",
      "Epoch 65/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6725 - categorical_accuracy: 0.7202 - val_loss: 1.2104 - val_categorical_accuracy: 0.5400\n",
      "Epoch 66/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6519 - categorical_accuracy: 0.7343 - val_loss: 1.2996 - val_categorical_accuracy: 0.5517\n",
      "Epoch 67/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6355 - categorical_accuracy: 0.7427 - val_loss: 1.3157 - val_categorical_accuracy: 0.5408\n",
      "Epoch 68/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6236 - categorical_accuracy: 0.7491 - val_loss: 1.3395 - val_categorical_accuracy: 0.5667\n",
      "Epoch 69/100\n",
      "22048/22048 [==============================] - 52s - loss: 0.6147 - categorical_accuracy: 0.7549 - val_loss: 1.2837 - val_categorical_accuracy: 0.5580\n",
      "Epoch 70/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.6070 - categorical_accuracy: 0.7629 - val_loss: 1.4266 - val_categorical_accuracy: 0.5660\n",
      "Epoch 71/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5998 - categorical_accuracy: 0.7639 - val_loss: 1.4780 - val_categorical_accuracy: 0.5630\n",
      "Epoch 72/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5921 - categorical_accuracy: 0.7651 - val_loss: 1.3876 - val_categorical_accuracy: 0.5472\n",
      "Epoch 73/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5859 - categorical_accuracy: 0.7694 - val_loss: 1.2773 - val_categorical_accuracy: 0.5628\n",
      "Epoch 74/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5812 - categorical_accuracy: 0.7702 - val_loss: 1.3399 - val_categorical_accuracy: 0.5647\n",
      "Epoch 75/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5730 - categorical_accuracy: 0.7760 - val_loss: 1.4098 - val_categorical_accuracy: 0.5750\n",
      "Epoch 76/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5694 - categorical_accuracy: 0.7780 - val_loss: 1.4131 - val_categorical_accuracy: 0.5582\n",
      "Epoch 77/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5641 - categorical_accuracy: 0.7774 - val_loss: 1.4932 - val_categorical_accuracy: 0.5700\n",
      "Epoch 78/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5629 - categorical_accuracy: 0.7793 - val_loss: 1.5052 - val_categorical_accuracy: 0.5762\n",
      "Epoch 79/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5536 - categorical_accuracy: 0.7822 - val_loss: 1.4860 - val_categorical_accuracy: 0.5470\n",
      "Epoch 80/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5540 - categorical_accuracy: 0.7821 - val_loss: 1.5079 - val_categorical_accuracy: 0.5837\n",
      "Epoch 81/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5455 - categorical_accuracy: 0.7890 - val_loss: 1.6833 - val_categorical_accuracy: 0.5458\n",
      "Epoch 82/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5448 - categorical_accuracy: 0.7834 - val_loss: 1.7105 - val_categorical_accuracy: 0.5820\n",
      "Epoch 83/100\n",
      "22048/22048 [==============================] - 53s - loss: 0.5388 - categorical_accuracy: 0.7908 - val_loss: 1.6318 - val_categorical_accuracy: 0.5660\n",
      "Epoch 84/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5352 - categorical_accuracy: 0.7904 - val_loss: 1.6482 - val_categorical_accuracy: 0.5770\n",
      "Epoch 85/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5353 - categorical_accuracy: 0.7900 - val_loss: 1.7631 - val_categorical_accuracy: 0.5705\n",
      "Epoch 86/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5319 - categorical_accuracy: 0.7965 - val_loss: 1.5441 - val_categorical_accuracy: 0.5520\n",
      "Epoch 87/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5273 - categorical_accuracy: 0.7949 - val_loss: 1.8243 - val_categorical_accuracy: 0.5598\n",
      "Epoch 88/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5274 - categorical_accuracy: 0.7943 - val_loss: 1.9926 - val_categorical_accuracy: 0.5693\n",
      "Epoch 89/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5210 - categorical_accuracy: 0.7966 - val_loss: 1.6132 - val_categorical_accuracy: 0.5793\n",
      "Epoch 90/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5205 - categorical_accuracy: 0.7976 - val_loss: 1.7933 - val_categorical_accuracy: 0.5588\n",
      "Epoch 91/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5164 - categorical_accuracy: 0.7985 - val_loss: 1.5825 - val_categorical_accuracy: 0.5822\n",
      "Epoch 92/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5136 - categorical_accuracy: 0.8002 - val_loss: 1.5494 - val_categorical_accuracy: 0.5817\n",
      "Epoch 93/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5112 - categorical_accuracy: 0.8008 - val_loss: 1.7726 - val_categorical_accuracy: 0.5692\n",
      "Epoch 94/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5095 - categorical_accuracy: 0.8045 - val_loss: 1.6474 - val_categorical_accuracy: 0.5850\n",
      "Epoch 95/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5036 - categorical_accuracy: 0.8018 - val_loss: 2.0665 - val_categorical_accuracy: 0.5810\n",
      "Epoch 96/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.5021 - categorical_accuracy: 0.8048 - val_loss: 1.5778 - val_categorical_accuracy: 0.5842\n",
      "Epoch 97/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.4973 - categorical_accuracy: 0.8043 - val_loss: 1.8131 - val_categorical_accuracy: 0.5820\n",
      "Epoch 98/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.4988 - categorical_accuracy: 0.8077 - val_loss: 2.0237 - val_categorical_accuracy: 0.5783\n",
      "Epoch 99/100\n",
      "22048/22048 [==============================] - 54s - loss: 0.4943 - categorical_accuracy: 0.8068 - val_loss: 1.9284 - val_categorical_accuracy: 0.5722\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22048/22048 [==============================] - 51s - loss: 0.4916 - categorical_accuracy: 0.8113 - val_loss: 2.0274 - val_categorical_accuracy: 0.5645\n"
     ]
    }
   ],
   "source": [
    "#features = ['Volume_BTC', 'Price_lagged', 'CoinbaseTrend']\n",
    "#features = ['Volume_BTC', 'Bitcoin_Adj', 'Price_lagged']\n",
    "#features = ['Volume_BTC', 'Price_lagged']\n",
    "key_features = [\n",
    "    'Volume_BTC',\n",
    "    'Bitcoin_Adj', \n",
    "    'Price_lagged', \n",
    "    'CoinbaseTrend',\n",
    "    'BlockchainTrend',\n",
    "    'BubbleTrend'\n",
    "]\n",
    "rnn = build_model(key_features, data_length) \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "history = rnn.fit(\n",
    "    [\n",
    "        X_train_volume[:-2000],\n",
    "        X_train_trends[:-2000],\n",
    "        X_train_lagged_price[:-2000],\n",
    "        X_train_trends_coinbase[:-2000],\n",
    "        X_train_trends_blockchain[:-2000],\n",
    "        X_train_trends_bubble[:-2000]\n",
    "    ],\n",
    "    [\n",
    "        Y_train_is_spike_onehot[:-2000]\n",
    "    ]\n",
    "    ,\n",
    "    validation_data=(\n",
    "        [\n",
    "            X_test_volume,\n",
    "            X_test_trends,\n",
    "            X_test_lagged_price,\n",
    "            X_test_trends_coinbase,\n",
    "            X_test_trends_blockchain,\n",
    "            X_test_trends_bubble\n",
    "        ],\n",
    "        [\n",
    "            Y_test_is_spike_onehot\n",
    "        ]),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "      tensorboard_callback\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Volume_BTC (InputLayer)          (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Bitcoin_Adj (InputLayer)         (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "Price_lagged (InputLayer)        (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "CoinbaseTrend (InputLayer)       (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "BlockchainTrend (InputLayer)     (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "BubbleTrend (InputLayer)         (None, 24, 1)         0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 24, 32)        4352        Volume_BTC[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 24, 32)        4352        Bitcoin_Adj[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                    (None, 24, 32)        4352        Price_lagged[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                   (None, 24, 32)        4352        CoinbaseTrend[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                   (None, 24, 32)        4352        BlockchainTrend[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                   (None, 24, 32)        4352        BubbleTrend[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 24, 192)       0           lstm_7[0][0]                     \n",
      "                                                                   lstm_8[0][0]                     \n",
      "                                                                   lstm_9[0][0]                     \n",
      "                                                                   lstm_10[0][0]                    \n",
      "                                                                   lstm_11[0][0]                    \n",
      "                                                                   lstm_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 24, 16)        3088        concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 384)           0           time_distributed_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "IsSpike (Dense)                  (None, 3)             1155        flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 30,355\n",
      "Trainable params: 30,355\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "display(rnn.summary())\n",
    "#plot_model(rnn, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f97f247c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 5s     \n",
      "\n",
      "\n",
      "Accuracy: 56.45%\n"
     ]
    }
   ],
   "source": [
    "score = rnn.evaluate(\n",
    "    [\n",
    "        X_test_volume,\n",
    "            X_test_trends,\n",
    "            X_test_lagged_price,\n",
    "            X_test_trends_coinbase,\n",
    "            X_test_trends_blockchain,\n",
    "            X_test_trends_bubble\n",
    "    ],\n",
    "    [\n",
    "        Y_test_is_spike_onehot\n",
    "    ])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDEmxP8HkX63CHtaaBIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f9056ee2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_size = int(len(X_volume) * 0.8)\n",
    "train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "# val_size = int(train_size * 0.95)\n",
    "# val_size = int(val_size/data_length) * data_length\n",
    "\n",
    "plt.plot(df['Close'].iloc[:train_size], label='Train')\n",
    "#plt.plot(df['Close'].iloc[val_size:train_size], label='Validation')\n",
    "plt.plot(df['Close'].iloc[train_size:], label='Test')\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "# TODO: maybe move around so that validation is a little before peak to 24000 ish and test is a little before peak to end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.97967025e-03,   9.45729087e-04,   9.97074604e-01],\n",
       "       [  1.47210842e-03,   9.98454690e-01,   7.32546468e-05],\n",
       "       [  6.95100069e-01,   8.69228616e-02,   2.17977047e-01],\n",
       "       ..., \n",
       "       [  1.72407948e-03,   9.96841550e-01,   1.43446843e-03],\n",
       "       [  8.89076173e-01,   2.16716472e-02,   8.92522261e-02],\n",
       "       [  2.35333353e-01,   2.53780093e-03,   7.62128890e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0         -1    -1.0\n",
       "1          1     1.0\n",
       "2          0     0.0\n",
       "3          1     1.0\n",
       "4         -1    -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = rnn.predict( \n",
    "    [\n",
    "       X_test_volume,\n",
    "            X_test_trends,\n",
    "            X_test_lagged_price,\n",
    "            X_test_trends_coinbase,\n",
    "            X_test_trends_blockchain,\n",
    "            X_test_trends_bubble\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "display(yhat)\n",
    "\n",
    "inverted_yhat = np.argmax(yhat,axis=1) #returns INDICES of max \n",
    "onehot_to_val_dict = {0: 0, 1: 1, 2:-1 }\n",
    "\n",
    "inverted_yhat_arr = np.asarray(inverted_yhat)\n",
    "predicted = [onehot_to_val_dict[i] for i in inverted_yhat_arr]\n",
    "\n",
    "\n",
    "df_pred_output = pd.DataFrame(predicted, columns=['predicted'])\n",
    "df_pred_output['actual'] = Y_test_is_spike\n",
    "#df_pred_output['index_output'] = inverted_yhat\n",
    "display(df_pred_output.head())\n",
    "\n",
    "correct = (df_pred_output['actual'].values == df_pred_output['predicted'].values)\n",
    "accuracy = correct.sum() / correct.size\n",
    "display(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(\"checkresult.xlsx\",  engine='xlsxwriter', options={'remove_timezone': True})\n",
    "df_pred_output.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON# serial \n",
    "model_json = rnn.to_json()\n",
    "with open(\"model_classification_v1data_200epochs_10length.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "rnn.save_weights(\"model_classification_v1data_200epochs_10length.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>1443</td>\n",
       "      <td>342</td>\n",
       "      <td>481</td>\n",
       "      <td>2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>521</td>\n",
       "      <td>655</td>\n",
       "      <td>298</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>666</td>\n",
       "      <td>391</td>\n",
       "      <td>1203</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2630</td>\n",
       "      <td>1388</td>\n",
       "      <td>1982</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    -1     0     1   All\n",
       "Actual                           \n",
       "-1.0       1443   342   481  2266\n",
       "0.0         521   655   298  1474\n",
       "1.0         666   391  1203  2260\n",
       "All        2630  1388  1982  6000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#print(metrics.confusion_matrix(df_pred_output['actual'].values, df_pred_output['predicted'].values,labels=[0,1,-1]))\n",
    "\n",
    "confusion_matrix = pd.crosstab(df_pred_output['actual'].values, df_pred_output['predicted'].values, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to check what the rnn actually learned \n",
    "# visualize predicted vs actual to get insight into this \n",
    "\n",
    "# try with instead of just 10% biggest changes, maybe with 25% \n",
    "# is it just learning from the previous prices, or is google trends actually helping \n",
    "# -> run rnn without google trends \n",
    "\n",
    "\n",
    "# I have a master_df_v2 now so try that - this one has 0.3 as cutoff for is Spike \n",
    "# Have to eventually get validation data - also get overall newer more data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
