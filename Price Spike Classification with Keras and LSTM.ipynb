{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# features is a list of strings of feature names \n",
    "\n",
    "def build_model(features, data_length):\n",
    "    \n",
    "    inputs_list = [] \n",
    "    for feature_name in features:\n",
    "        inputs_list.append((Input(shape=(data_length,1), name=feature_name)))\n",
    "    \n",
    "    layers = [] \n",
    "    for i, input_name in enumerate(inputs_list): \n",
    "        layers.append(LSTM(64, return_sequences=False)(inputs_list[i]) )\n",
    "        \n",
    "    output = concatenate(layers) \n",
    "    output = Dense(3, activation='softmax', name='IsSpike')(output)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs = inputs_list,\n",
    "        outputs = [output]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    \n",
    "\n",
    "data_length = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.471970</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463316</td>\n",
       "      <td>0.439996</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725079</td>\n",
       "      <td>0.529463</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210661</td>\n",
       "      <td>0.416611</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.594148</td>\n",
       "      <td>0.445509</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Volume_BTC  Bitcoin_Adj     Close  Price_lagged  Is Spike\n",
       "1    0.776791     0.471970  0.484557      0.484557       1.0\n",
       "2    0.463316     0.439996  0.538331      0.538331       0.0\n",
       "3    0.725079     0.529463  0.520715      0.520715      -1.0\n",
       "4    0.210661     0.416611  0.566098      0.566098       0.0\n",
       "5    0.594148     0.445509  0.568881      0.568881       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28073</th>\n",
       "      <td>0.458128</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.551945</td>\n",
       "      <td>0.551945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28074</th>\n",
       "      <td>0.598396</td>\n",
       "      <td>0.445234</td>\n",
       "      <td>0.530895</td>\n",
       "      <td>0.530895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28075</th>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.485610</td>\n",
       "      <td>0.539689</td>\n",
       "      <td>0.539689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28076</th>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.461015</td>\n",
       "      <td>0.682808</td>\n",
       "      <td>0.682808</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28077</th>\n",
       "      <td>0.632874</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.532150</td>\n",
       "      <td>0.532150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume_BTC  Bitcoin_Adj     Close  Price_lagged  Is Spike\n",
       "28073    0.458128     0.453625  0.551945      0.551945       0.0\n",
       "28074    0.598396     0.445234  0.530895      0.530895       0.0\n",
       "28075    0.488000     0.485610  0.539689      0.539689       0.0\n",
       "28076    0.553633     0.461015  0.682808      0.682808      -1.0\n",
       "28077    0.632874     0.453625  0.532150      0.532150       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "master_df = pd.read_csv('C:/Users/Shoya/surf/data/master_df.csv', encoding='latin1')\n",
    "df = master_df[['Timestamp', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Date(UTC)', 'Bitcoin (Adj.Overlap)', \n",
    "               'Close Price % Change', 'Close Price % Change (Abs)', 'Is Spike']]\n",
    "\n",
    "# lag inputs depending on data_length \n",
    "df['Price_lagged'] = df['Close']#.shift(data_length)\n",
    "df['Volume_BTC'] = df['Volume_(BTC)']#.shift(data_length)\n",
    "df['Bitcoin_Adj'] = df['Bitcoin (Adj.Overlap)']#.shift(data_length)\n",
    "\n",
    "df = df.dropna()\n",
    "cols = ['Volume_BTC','Bitcoin_Adj', 'Close', 'Price_lagged']\n",
    "\n",
    "# Stationalize Data by taking log differences\n",
    "data_array = np.diff(np.log(df[cols]), axis=0)\n",
    "\n",
    "# Min-Max Scale \n",
    "\n",
    "scalers = {}\n",
    "datas = [] \n",
    "\n",
    "df_scaled = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(cols)): \n",
    "    scalers[cols[i]] = MinMaxScaler()\n",
    "    #print('data', data_array[:,i])\n",
    "    \n",
    "    col_data = data_array[:,i]\n",
    "    col_data = np.reshape(col_data, (len(col_data), 1))\n",
    "    \n",
    "    data = scalers[cols[i]].fit_transform( col_data )  #:, np.newaxis\n",
    "    #print('scaled', data)\n",
    "    data = np.reshape(data, (1, len(data)))\n",
    "    df_scaled[cols[i]] = data[0]\n",
    "    \n",
    "df_scaled['Is Spike'] = df['Is Spike']\n",
    "df_scaled.dropna(inplace=True)\n",
    "display(df_scaled.head())\n",
    "display(df_scaled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# split and reshape data to feed into RNN\n",
    "\n",
    "# X_timestamp = df_scaled['Timestamp'].values\n",
    "X_volume = df_scaled['Volume_BTC'].values\n",
    "X_trends = df_scaled['Bitcoin_Adj'].values\n",
    "X_lagged_price = df_scaled['Price_lagged'].values\n",
    "\n",
    "Y_is_spike = df_scaled['Is Spike'].values \n",
    "\n",
    "train_size = int(len(X_volume) * 0.85)\n",
    "train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "test_size_index = int(len(X_volume)/data_length)*data_length\n",
    "\n",
    "X_train_volume = []\n",
    "X_test_volume = [] \n",
    "X_train_trends = []\n",
    "X_test_trends = []\n",
    "X_train_lagged_price = []\n",
    "X_test_lagged_price = []\n",
    "Y_train_is_spike = [] \n",
    "Y_test_is_spike = [] \n",
    "\n",
    "for i in range(train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = []\n",
    "    price_temp = []\n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[i+j])\n",
    "        trends_temp.append(X_trends[i+j])\n",
    "        price_temp.append(X_lagged_price[i+j])\n",
    "    X_train_volume.append(vol_temp)\n",
    "    X_train_trends.append(trends_temp)\n",
    "    X_train_lagged_price.append(price_temp)\n",
    "    \n",
    "    Y_train_is_spike.append(Y_is_spike[i+data_length])\n",
    "\n",
    "for i in range(test_size_index-train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = [] \n",
    "    price_temp = [] \n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[train_size+i+j])\n",
    "        trends_temp.append(X_trends[train_size+i+j])\n",
    "        price_temp.append(X_lagged_price[train_size+i+j])\n",
    "    X_test_volume.append(vol_temp)\n",
    "    X_test_trends.append(trends_temp)\n",
    "    X_test_lagged_price.append(price_temp)\n",
    "    \n",
    "    Y_test_is_spike.append(Y_is_spike[train_size+i+data_length])\n",
    "    \n",
    "X_train_volume = np.array(X_train_volume)\n",
    "X_test_volume =  np.array(X_test_volume)\n",
    "X_train_trends = np.array(X_train_trends)\n",
    "X_test_trends = np.array(X_test_trends)\n",
    "X_train_lagged_price = np.array(X_train_lagged_price)\n",
    "X_test_lagged_price = np.array(X_test_lagged_price)\n",
    "Y_train_is_spike =  np.array(Y_train_is_spike)\n",
    "Y_test_is_spike = np.array(Y_test_is_spike)\n",
    "    \n",
    "    \n",
    "Y_train_is_spike_onehot = to_categorical(Y_train_is_spike, num_classes=3)\n",
    "Y_test_is_spike_onehot = to_categorical(Y_test_is_spike,num_classes=3)\n",
    "display(Y_train_is_spike)\n",
    "\n",
    "# y = pd.DataFrame(Y_train_is_spike_onehot)\n",
    "# y['actual'] = Y_train_is_spike\n",
    "# display(y.head(25))\n",
    "    \n",
    "# display(X_train_trends.shape)\n",
    "# display(Y_train_is_spike.shape)\n",
    "\n",
    "#display(X_train_lagged_price)\n",
    "#display(Y_train_is_spike)\n",
    "\n",
    "# df_train = pd.DataFrame(X_train_lagged_price)\n",
    "# df_train['label'] = Y_train_is_spike\n",
    "# display(df_train.tail(20))\n",
    "# display(df_scaled.head(30))\n",
    "# display(df_train.head(30))\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "# # X_train_timestamp, X_test_timestamp = X_timestamp[:train_size], X_timestamp[train_size:test_size_index ]\n",
    "# X_train_volume, X_test_volume = X_volume[:train_size], X_volume[train_size:test_size_index ]\n",
    "# X_train_trends, X_test_trends = X_trends[:train_size], X_trends[train_size:test_size_index ]\n",
    "# X_train_lagged_price, X_test_lagged_price = X_lagged_price[:train_size], X_lagged_price[train_size:test_size_index ]\n",
    "\n",
    "# # becasue I lagged the x inputs, I should forward the Y's by the data_length as well \n",
    "# Y_train_is_spike, Y_test_is_spike = Y_is_spike[data_length:train_size], Y_is_spike[train_size+data_length:test_size_index ]\n",
    "\n",
    "\n",
    "# # X.shape is (samples, timesteps, dimension) \n",
    "# # timestemps is 15, samples is just however many nobs there are (but it doesn't matter, so it should be None)\n",
    "\n",
    "\n",
    "X_train_volume = np.reshape(X_train_volume, (X_train_volume.shape[0],data_length,1) ) \n",
    "X_train_trends = np.reshape(X_train_trends, (X_train_trends.shape[0],data_length,1) ) \n",
    "X_train_lagged_price = np.reshape(X_train_lagged_price, (X_train_lagged_price.shape[0], data_length, 1))\n",
    "\n",
    "X_test_volume = np.reshape(X_test_volume, (X_test_volume.shape[0],data_length,1) ) \n",
    "X_test_trends = np.reshape(X_test_trends, (X_test_trends.shape[0],data_length,1) )  \n",
    "X_test_lagged_price = np.reshape(X_test_lagged_price, (X_test_lagged_price.shape[0],data_length,1))\n",
    "\n",
    "\n",
    "# # X_train_timestamp = np.reshape(X_train_timestamp, (int(X_train_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_volume = np.reshape(X_train_volume, (int(X_train_volume.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_trends = np.reshape(X_train_trends, (int(X_train_trends.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_lagged_price = np.reshape(X_train_lagged_price, (int(X_train_lagged_price.shape[0]/data_length), data_length, 1))\n",
    "\n",
    "# # X_test_timestamp = np.reshape(X_test_timestamp, (int(X_test_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "# X_test_volume = np.reshape(X_test_volume, (int(X_test_volume.shape[0]/data_length),data_length,1) ) \n",
    "# X_test_trends = np.reshape(X_test_trends, (int(X_test_trends.shape[0]/data_length),data_length,1) )  \n",
    "# X_test_lagged_price = np.reshape(X_test_lagged_price, (int(X_test_lagged_price.shape[0]/data_length),data_length,1))\n",
    "\n",
    "\n",
    "# # Don't need the 1 for the third dimension for Y's??\n",
    "\n",
    "\n",
    "# Y_train_is_spike = np.reshape(Y_train_is_spike, (int(Y_train_is_spike.shape[0]/data_length),  data_length) ) \n",
    "# Y_test_is_spike = np.reshape(Y_test_is_spike, (int(Y_test_is_spike.shape[0]/data_length),  data_length) )\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "\n",
    "# instead of using input 1,2,3,4,5,6,7,8,9,10 to predict output for 11,12,13,14,15,16,17,18,19,20\n",
    "# I want to use input 1,2,3,4,5,6,7,8,9,10 to predict output for 11, then 2,3,4,5,6,7,8,9,10,11 to predict output for 12 \n",
    "\n",
    "# right now I am actually feeding input 1,2,3,4,5,6,7,8,9,10 to predict output for 1,2,3,4,5,6,7,8,9,10. \n",
    "# instead I should at least feed 1,2,3..8,9,10 to predict 11,12,13,14,15,16,17,18,19,20 -> lag everything by data_length! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23850 samples, validate on 4200 samples\n",
      "Epoch 1/20\n",
      "23850/23850 [==============================] - 37s - loss: 0.5482 - categorical_accuracy: 0.8432 - val_loss: 1.3898 - val_categorical_accuracy: 0.5481\n",
      "Epoch 2/20\n",
      "23850/23850 [==============================] - 37s - loss: 0.5443 - categorical_accuracy: 0.8443 - val_loss: 1.3404 - val_categorical_accuracy: 0.5481\n",
      "Epoch 3/20\n",
      "23850/23850 [==============================] - 36s - loss: 0.5435 - categorical_accuracy: 0.8443 - val_loss: 1.1786 - val_categorical_accuracy: 0.5481\n",
      "Epoch 4/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.5430 - categorical_accuracy: 0.8443 - val_loss: 1.3155 - val_categorical_accuracy: 0.5481\n",
      "Epoch 5/20\n",
      "23850/23850 [==============================] - 36s - loss: 0.5419 - categorical_accuracy: 0.8443 - val_loss: 1.2251 - val_categorical_accuracy: 0.5481\n",
      "Epoch 6/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.5414 - categorical_accuracy: 0.8443 - val_loss: 1.2506 - val_categorical_accuracy: 0.5481\n",
      "Epoch 7/20\n",
      "23850/23850 [==============================] - 37s - loss: 0.5408 - categorical_accuracy: 0.8443 - val_loss: 1.2360 - val_categorical_accuracy: 0.5481\n",
      "Epoch 8/20\n",
      "23850/23850 [==============================] - 34s - loss: 0.5395 - categorical_accuracy: 0.8443 - val_loss: 1.2882 - val_categorical_accuracy: 0.5481\n",
      "Epoch 9/20\n",
      "23850/23850 [==============================] - 34s - loss: 0.5350 - categorical_accuracy: 0.8443 - val_loss: 1.3124 - val_categorical_accuracy: 0.5481\n",
      "Epoch 10/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.5227 - categorical_accuracy: 0.8431 - val_loss: 1.1798 - val_categorical_accuracy: 0.5495\n",
      "Epoch 11/20\n",
      "23850/23850 [==============================] - 34s - loss: 0.5134 - categorical_accuracy: 0.8437 - val_loss: 1.1032 - val_categorical_accuracy: 0.5540\n",
      "Epoch 12/20\n",
      "23850/23850 [==============================] - 34s - loss: 0.5036 - categorical_accuracy: 0.8438 - val_loss: 1.0329 - val_categorical_accuracy: 0.5631\n",
      "Epoch 13/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4952 - categorical_accuracy: 0.8447 - val_loss: 1.0569 - val_categorical_accuracy: 0.5571\n",
      "Epoch 14/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4866 - categorical_accuracy: 0.8442 - val_loss: 1.1039 - val_categorical_accuracy: 0.5540\n",
      "Epoch 15/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4750 - categorical_accuracy: 0.8443 - val_loss: 1.0868 - val_categorical_accuracy: 0.5631\n",
      "Epoch 16/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4628 - categorical_accuracy: 0.8475 - val_loss: 1.0929 - val_categorical_accuracy: 0.5824\n",
      "Epoch 17/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4559 - categorical_accuracy: 0.8477 - val_loss: 0.9800 - val_categorical_accuracy: 0.5838\n",
      "Epoch 18/20\n",
      "23850/23850 [==============================] - 34s - loss: 0.4462 - categorical_accuracy: 0.8479 - val_loss: 0.8830 - val_categorical_accuracy: 0.6043\n",
      "Epoch 19/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4401 - categorical_accuracy: 0.8499 - val_loss: 0.9519 - val_categorical_accuracy: 0.5869\n",
      "Epoch 20/20\n",
      "23850/23850 [==============================] - 35s - loss: 0.4337 - categorical_accuracy: 0.8509 - val_loss: 0.9162 - val_categorical_accuracy: 0.5971\n"
     ]
    }
   ],
   "source": [
    "features = ['Volume_BTC', 'Bitcoin_Adj', 'Price_lagged']\n",
    "\n",
    "rnn = build_model(features, 10) \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "history = rnn.fit(\n",
    "    [\n",
    "        #X_train_timestamp,\n",
    "        X_train_volume,\n",
    "        X_train_trends,\n",
    "        X_train_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_train_is_spike_onehot\n",
    "    ]\n",
    "    ,\n",
    "    validation_data=(\n",
    "        [\n",
    "            #X_test_timestamp,\n",
    "            X_test_volume,\n",
    "            X_test_trends,\n",
    "            X_test_lagged_price\n",
    "        ],\n",
    "        [\n",
    "            Y_test_is_spike_onehot\n",
    "        ]),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "      tensorboard_callback\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4192/4200 [============================>.] - ETA: 0s\n",
      "\n",
      "Accuracy: 59.71%\n"
     ]
    }
   ],
   "source": [
    "score = rnn.evaluate(\n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_test_is_spike_onehot\n",
    "    ])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89756489,  0.08310197,  0.01933317],\n",
       "       [ 0.84383726,  0.09476137,  0.0614014 ],\n",
       "       [ 0.95636821,  0.01410425,  0.02952744],\n",
       "       ..., \n",
       "       [ 0.51034886,  0.39668763,  0.09296344],\n",
       "       [ 0.41741222,  0.50381827,  0.07876941],\n",
       "       [ 0.39037132,  0.52225763,  0.08737103]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted  actual\n",
       "0             0    -1.0\n",
       "1             0     0.0\n",
       "2             0     0.0\n",
       "3             0     0.0\n",
       "4             0     0.0\n",
       "5             0     0.0\n",
       "6             0     0.0\n",
       "7             0     0.0\n",
       "8             0     0.0\n",
       "9             0     0.0\n",
       "10            0     0.0\n",
       "11            0     0.0\n",
       "12            0     0.0\n",
       "13            0     0.0\n",
       "14            0    -1.0\n",
       "15            0     0.0\n",
       "16            0     0.0\n",
       "17            0     0.0\n",
       "18            0    -1.0\n",
       "19            1     0.0\n",
       "20            0     0.0\n",
       "21            0    -1.0\n",
       "22            0     0.0\n",
       "23            0     0.0\n",
       "24            0     0.0\n",
       "25            0     0.0\n",
       "26            0     0.0\n",
       "27            0     0.0\n",
       "28            0     0.0\n",
       "29            0     0.0\n",
       "...         ...     ...\n",
       "4170          0     0.0\n",
       "4171          0     0.0\n",
       "4172          0     0.0\n",
       "4173          0     0.0\n",
       "4174          0     0.0\n",
       "4175          0     0.0\n",
       "4176          0    -1.0\n",
       "4177          0     0.0\n",
       "4178          0     0.0\n",
       "4179          0     0.0\n",
       "4180          0     0.0\n",
       "4181          0     0.0\n",
       "4182          0     0.0\n",
       "4183          0    -1.0\n",
       "4184          0     0.0\n",
       "4185          0    -1.0\n",
       "4186          0     0.0\n",
       "4187          0     0.0\n",
       "4188          1     0.0\n",
       "4189          0     0.0\n",
       "4190          0     0.0\n",
       "4191          0     0.0\n",
       "4192          0     0.0\n",
       "4193          0     0.0\n",
       "4194          0    -1.0\n",
       "4195          0    -1.0\n",
       "4196          0    -1.0\n",
       "4197          0     0.0\n",
       "4198          1     0.0\n",
       "4199          1     0.0\n",
       "\n",
       "[4200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5971428571428572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = rnn.predict( \n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "display(yhat)\n",
    "\n",
    "inverted_yhat = np.argmax(yhat,axis=1) #returns INDICES of max \n",
    "onehot_to_val_dict = {0: 0, 1: 1, 2:-1 }\n",
    "\n",
    "inverted_yhat_arr = np.asarray(inverted_yhat)\n",
    "predicted = [onehot_to_val_dict[i] for i in inverted_yhat_arr]\n",
    "\n",
    "\n",
    "df_pred_output = pd.DataFrame(predicted, columns=['predicted'])\n",
    "df_pred_output['actual'] = Y_test_is_spike\n",
    "#df_pred_output['index_output'] = inverted_yhat\n",
    "display(df_pred_output)\n",
    "\n",
    "# correct = (df_pred_output['actual'].values == df_pred_output['predicted'].values)\n",
    "# accuracy = correct.sum() / correct.size\n",
    "# display(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON# serial \n",
    "model_json = rnn.to_json()\n",
    "with open(\"model_classification.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "rnn.save_weights(\"model_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 222  586  151]\n",
      " [  64 1908  330]\n",
      " [  34  527  378]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(df_pred_output['actual'], df_pred_output['predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
