{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# features is a list of strings of feature names \n",
    "\n",
    "def build_model(features, data_length):\n",
    "    \n",
    "    inputs_list = [] \n",
    "    for feature_name in features:\n",
    "        inputs_list.append((Input(shape=(data_length,1), name=feature_name)))\n",
    "    \n",
    "    layers = [] \n",
    "    for i, input_name in enumerate(inputs_list): \n",
    "        layers.append(LSTM(64, return_sequences=False)(inputs_list[i]) )\n",
    "        \n",
    "    output = concatenate(layers) \n",
    "    output = Dense(3, activation='softmax', name='IsSpike')(output)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs = inputs_list,\n",
    "        outputs = [output]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    \n",
    "\n",
    "data_length = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776791</td>\n",
       "      <td>0.471970</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>0.484557</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463316</td>\n",
       "      <td>0.439996</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.538331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725079</td>\n",
       "      <td>0.529463</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>0.520715</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210661</td>\n",
       "      <td>0.416611</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.566098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.594148</td>\n",
       "      <td>0.445509</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.568881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Volume_BTC  Bitcoin_Adj     Close  Price_lagged  Is Spike\n",
       "1    0.776791     0.471970  0.484557      0.484557       1.0\n",
       "2    0.463316     0.439996  0.538331      0.538331       0.0\n",
       "3    0.725079     0.529463  0.520715      0.520715      -1.0\n",
       "4    0.210661     0.416611  0.566098      0.566098       0.0\n",
       "5    0.594148     0.445509  0.568881      0.568881       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28073</th>\n",
       "      <td>0.458128</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.551945</td>\n",
       "      <td>0.551945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28074</th>\n",
       "      <td>0.598396</td>\n",
       "      <td>0.445234</td>\n",
       "      <td>0.530895</td>\n",
       "      <td>0.530895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28075</th>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.485610</td>\n",
       "      <td>0.539689</td>\n",
       "      <td>0.539689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28076</th>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.461015</td>\n",
       "      <td>0.682808</td>\n",
       "      <td>0.682808</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28077</th>\n",
       "      <td>0.632874</td>\n",
       "      <td>0.453625</td>\n",
       "      <td>0.532150</td>\n",
       "      <td>0.532150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume_BTC  Bitcoin_Adj     Close  Price_lagged  Is Spike\n",
       "28073    0.458128     0.453625  0.551945      0.551945       0.0\n",
       "28074    0.598396     0.445234  0.530895      0.530895       0.0\n",
       "28075    0.488000     0.485610  0.539689      0.539689       0.0\n",
       "28076    0.553633     0.461015  0.682808      0.682808      -1.0\n",
       "28077    0.632874     0.453625  0.532150      0.532150       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "master_df = pd.read_csv('C:/Users/Shoya/surf/data/master_df.csv', encoding='latin1')\n",
    "df = master_df[['Timestamp', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Date(UTC)', 'Bitcoin (Adj.Overlap)', \n",
    "               'Close Price % Change', 'Close Price % Change (Abs)', 'Is Spike']]\n",
    "\n",
    "# lag inputs depending on data_length \n",
    "df['Price_lagged'] = df['Close']#.shift(data_length)\n",
    "df['Volume_BTC'] = df['Volume_(BTC)']#.shift(data_length)\n",
    "df['Bitcoin_Adj'] = df['Bitcoin (Adj.Overlap)']#.shift(data_length)\n",
    "\n",
    "df = df.dropna()\n",
    "cols = ['Volume_BTC','Bitcoin_Adj', 'Close', 'Price_lagged']\n",
    "\n",
    "# Stationalize Data by taking log differences\n",
    "data_array = np.diff(np.log(df[cols]), axis=0)\n",
    "\n",
    "# Min-Max Scale \n",
    "\n",
    "scalers = {}\n",
    "datas = [] \n",
    "\n",
    "df_scaled = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(cols)): \n",
    "    scalers[cols[i]] = MinMaxScaler()\n",
    "    #print('data', data_array[:,i])\n",
    "    \n",
    "    col_data = data_array[:,i]\n",
    "    col_data = np.reshape(col_data, (len(col_data), 1))\n",
    "    \n",
    "    data = scalers[cols[i]].fit_transform( col_data )  #:, np.newaxis\n",
    "    #print('scaled', data)\n",
    "    data = np.reshape(data, (1, len(data)))\n",
    "    df_scaled[cols[i]] = data[0]\n",
    "    \n",
    "df_scaled['Is Spike'] = df['Is Spike']\n",
    "df_scaled.dropna(inplace=True)\n",
    "display(df_scaled.head())\n",
    "display(df_scaled.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# split and reshape data to feed into RNN\n",
    "\n",
    "# X_timestamp = df_scaled['Timestamp'].values\n",
    "X_volume = df_scaled['Volume_BTC'].values\n",
    "X_trends = df_scaled['Bitcoin_Adj'].values\n",
    "X_lagged_price = df_scaled['Price_lagged'].values\n",
    "\n",
    "Y_is_spike = df_scaled['Is Spike'].values \n",
    "\n",
    "train_size = int(len(X_volume) * 0.85)\n",
    "train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "test_size_index = int(len(X_volume)/data_length)*data_length\n",
    "\n",
    "X_train_volume = []\n",
    "X_test_volume = [] \n",
    "X_train_trends = []\n",
    "X_test_trends = []\n",
    "X_train_lagged_price = []\n",
    "X_test_lagged_price = []\n",
    "Y_train_is_spike = [] \n",
    "Y_test_is_spike = [] \n",
    "\n",
    "for i in range(train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = []\n",
    "    price_temp = []\n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[i+j])\n",
    "        trends_temp.append(X_trends[i+j])\n",
    "        price_temp.append(X_lagged_price[i+j])\n",
    "    X_train_volume.append(vol_temp)\n",
    "    X_train_trends.append(trends_temp)\n",
    "    X_train_lagged_price.append(price_temp)\n",
    "    \n",
    "    Y_train_is_spike.append(Y_is_spike[i+data_length])\n",
    "\n",
    "for i in range(test_size_index-train_size-data_length):\n",
    "    vol_temp = []\n",
    "    trends_temp = [] \n",
    "    price_temp = [] \n",
    "    for j in range(data_length):\n",
    "        vol_temp.append(X_volume[train_size+i+j])\n",
    "        trends_temp.append(X_trends[train_size+i+j])\n",
    "        price_temp.append(X_lagged_price[train_size+i+j])\n",
    "    X_test_volume.append(vol_temp)\n",
    "    X_test_trends.append(trends_temp)\n",
    "    X_test_lagged_price.append(price_temp)\n",
    "    \n",
    "    Y_test_is_spike.append(Y_is_spike[train_size+i+data_length])\n",
    "    \n",
    "X_train_volume = np.array(X_train_volume)\n",
    "X_test_volume =  np.array(X_test_volume)\n",
    "X_train_trends = np.array(X_train_trends)\n",
    "X_test_trends = np.array(X_test_trends)\n",
    "X_train_lagged_price = np.array(X_train_lagged_price)\n",
    "X_test_lagged_price = np.array(X_test_lagged_price)\n",
    "Y_train_is_spike =  np.array(Y_train_is_spike)\n",
    "Y_test_is_spike = np.array(Y_test_is_spike)\n",
    "    \n",
    "    \n",
    "Y_train_is_spike_onehot = to_categorical(Y_train_is_spike, num_classes=3)\n",
    "Y_test_is_spike_onehot = to_categorical(Y_test_is_spike,num_classes=3)\n",
    "display(Y_train_is_spike)\n",
    "\n",
    "# y = pd.DataFrame(Y_train_is_spike_onehot)\n",
    "# y['actual'] = Y_train_is_spike\n",
    "# display(y.head(25))\n",
    "    \n",
    "# display(X_train_trends.shape)\n",
    "# display(Y_train_is_spike.shape)\n",
    "\n",
    "#display(X_train_lagged_price)\n",
    "#display(Y_train_is_spike)\n",
    "\n",
    "# df_train = pd.DataFrame(X_train_lagged_price)\n",
    "# df_train['label'] = Y_train_is_spike\n",
    "# display(df_train.tail(20))\n",
    "# display(df_scaled.head(30))\n",
    "# display(df_train.head(30))\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "# # X_train_timestamp, X_test_timestamp = X_timestamp[:train_size], X_timestamp[train_size:test_size_index ]\n",
    "# X_train_volume, X_test_volume = X_volume[:train_size], X_volume[train_size:test_size_index ]\n",
    "# X_train_trends, X_test_trends = X_trends[:train_size], X_trends[train_size:test_size_index ]\n",
    "# X_train_lagged_price, X_test_lagged_price = X_lagged_price[:train_size], X_lagged_price[train_size:test_size_index ]\n",
    "\n",
    "# # becasue I lagged the x inputs, I should forward the Y's by the data_length as well \n",
    "# Y_train_is_spike, Y_test_is_spike = Y_is_spike[data_length:train_size], Y_is_spike[train_size+data_length:test_size_index ]\n",
    "\n",
    "\n",
    "# # X.shape is (samples, timesteps, dimension) \n",
    "# # timestemps is 15, samples is just however many nobs there are (but it doesn't matter, so it should be None)\n",
    "\n",
    "\n",
    "X_train_volume = np.reshape(X_train_volume, (X_train_volume.shape[0],data_length,1) ) \n",
    "X_train_trends = np.reshape(X_train_trends, (X_train_trends.shape[0],data_length,1) ) \n",
    "X_train_lagged_price = np.reshape(X_train_lagged_price, (X_train_lagged_price.shape[0], data_length, 1))\n",
    "\n",
    "X_test_volume = np.reshape(X_test_volume, (X_test_volume.shape[0],data_length,1) ) \n",
    "X_test_trends = np.reshape(X_test_trends, (X_test_trends.shape[0],data_length,1) )  \n",
    "X_test_lagged_price = np.reshape(X_test_lagged_price, (X_test_lagged_price.shape[0],data_length,1))\n",
    "\n",
    "\n",
    "# # X_train_timestamp = np.reshape(X_train_timestamp, (int(X_train_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_volume = np.reshape(X_train_volume, (int(X_train_volume.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_trends = np.reshape(X_train_trends, (int(X_train_trends.shape[0]/data_length),data_length,1) ) \n",
    "# X_train_lagged_price = np.reshape(X_train_lagged_price, (int(X_train_lagged_price.shape[0]/data_length), data_length, 1))\n",
    "\n",
    "# # X_test_timestamp = np.reshape(X_test_timestamp, (int(X_test_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "# X_test_volume = np.reshape(X_test_volume, (int(X_test_volume.shape[0]/data_length),data_length,1) ) \n",
    "# X_test_trends = np.reshape(X_test_trends, (int(X_test_trends.shape[0]/data_length),data_length,1) )  \n",
    "# X_test_lagged_price = np.reshape(X_test_lagged_price, (int(X_test_lagged_price.shape[0]/data_length),data_length,1))\n",
    "\n",
    "\n",
    "# # Don't need the 1 for the third dimension for Y's??\n",
    "\n",
    "\n",
    "# Y_train_is_spike = np.reshape(Y_train_is_spike, (int(Y_train_is_spike.shape[0]/data_length),  data_length) ) \n",
    "# Y_test_is_spike = np.reshape(Y_test_is_spike, (int(Y_test_is_spike.shape[0]/data_length),  data_length) )\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "\n",
    "# instead of using input 1,2,3,4,5,6,7,8,9,10 to predict output for 11,12,13,14,15,16,17,18,19,20\n",
    "# I want to use input 1,2,3,4,5,6,7,8,9,10 to predict output for 11, then 2,3,4,5,6,7,8,9,10,11 to predict output for 12 \n",
    "\n",
    "# right now I am actually feeding input 1,2,3,4,5,6,7,8,9,10 to predict output for 1,2,3,4,5,6,7,8,9,10. \n",
    "# instead I should at least feed 1,2,3..8,9,10 to predict 11,12,13,14,15,16,17,18,19,20 -> lag everything by data_length! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5485 - categorical_accuracy: 0.8443    \n",
      "Epoch 2/40\n",
      "23850/23850 [==============================] - 22s - loss: 0.5431 - categorical_accuracy: 0.8443    \n",
      "Epoch 3/40\n",
      "23850/23850 [==============================] - 22s - loss: 0.5427 - categorical_accuracy: 0.8443    \n",
      "Epoch 4/40\n",
      "23850/23850 [==============================] - 24s - loss: 0.5427 - categorical_accuracy: 0.8443    \n",
      "Epoch 5/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5419 - categorical_accuracy: 0.8443    \n",
      "Epoch 6/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5410 - categorical_accuracy: 0.8443    \n",
      "Epoch 7/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5395 - categorical_accuracy: 0.8443    \n",
      "Epoch 8/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5383 - categorical_accuracy: 0.8443    \n",
      "Epoch 9/40\n",
      "23850/23850 [==============================] - 24s - loss: 0.5351 - categorical_accuracy: 0.8443    \n",
      "Epoch 10/40\n",
      "23850/23850 [==============================] - 24s - loss: 0.5314 - categorical_accuracy: 0.8443    \n",
      "Epoch 11/40\n",
      "23850/23850 [==============================] - 23s - loss: 0.5232 - categorical_accuracy: 0.8442    \n",
      "Epoch 12/40\n",
      "23850/23850 [==============================] - 24s - loss: 0.5078 - categorical_accuracy: 0.8447    \n",
      "Epoch 13/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.4860 - categorical_accuracy: 0.8456    \n",
      "Epoch 14/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4724 - categorical_accuracy: 0.8467    \n",
      "Epoch 15/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4595 - categorical_accuracy: 0.8486    \n",
      "Epoch 16/40\n",
      "23850/23850 [==============================] - 17s - loss: 0.4465 - categorical_accuracy: 0.8498    \n",
      "Epoch 17/40\n",
      "23850/23850 [==============================] - 17s - loss: 0.4393 - categorical_accuracy: 0.8495    \n",
      "Epoch 18/40\n",
      "23850/23850 [==============================] - 16s - loss: 0.4351 - categorical_accuracy: 0.8506    \n",
      "Epoch 19/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4275 - categorical_accuracy: 0.8519    \n",
      "Epoch 20/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4248 - categorical_accuracy: 0.8529    \n",
      "Epoch 21/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4204 - categorical_accuracy: 0.8526     ETA: 0s - loss: 0.4206 - categorical_accuracy: 0.85\n",
      "Epoch 22/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4159 - categorical_accuracy: 0.8542    \n",
      "Epoch 23/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.4114 - categorical_accuracy: 0.8545    \n",
      "Epoch 24/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.4069 - categorical_accuracy: 0.8553    \n",
      "Epoch 25/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.4067 - categorical_accuracy: 0.8555    \n",
      "Epoch 26/40\n",
      "23850/23850 [==============================] - 18s - loss: 0.4019 - categorical_accuracy: 0.8583    \n",
      "Epoch 27/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3977 - categorical_accuracy: 0.8566    \n",
      "Epoch 28/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.3946 - categorical_accuracy: 0.8590    \n",
      "Epoch 29/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3882 - categorical_accuracy: 0.8589    \n",
      "Epoch 30/40\n",
      "23850/23850 [==============================] - 19s - loss: 0.3831 - categorical_accuracy: 0.8613    \n",
      "Epoch 31/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3791 - categorical_accuracy: 0.8616    \n",
      "Epoch 32/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3734 - categorical_accuracy: 0.8654    \n",
      "Epoch 33/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3684 - categorical_accuracy: 0.8661    \n",
      "Epoch 34/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3577 - categorical_accuracy: 0.8690    \n",
      "Epoch 35/40\n",
      "23850/23850 [==============================] - 22s - loss: 0.3529 - categorical_accuracy: 0.8725    \n",
      "Epoch 36/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3483 - categorical_accuracy: 0.8735    \n",
      "Epoch 37/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3416 - categorical_accuracy: 0.8778    \n",
      "Epoch 38/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3365 - categorical_accuracy: 0.8797    \n",
      "Epoch 39/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3271 - categorical_accuracy: 0.8851    \n",
      "Epoch 40/40\n",
      "23850/23850 [==============================] - 20s - loss: 0.3237 - categorical_accuracy: 0.8849    \n"
     ]
    }
   ],
   "source": [
    "features = ['Volume_BTC', 'Bitcoin_Adj', 'Price_lagged']\n",
    "#features = ['Volume_BTC', 'Price_lagged']\n",
    "\n",
    "rnn = build_model(features, 10) \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "history = rnn.fit(\n",
    "    [\n",
    "        #X_train_timestamp,\n",
    "        X_train_volume,\n",
    "        X_train_trends,\n",
    "        X_train_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_train_is_spike_onehot\n",
    "    ]\n",
    "    ,\n",
    "#     validation_data=(\n",
    "#         [\n",
    "#             #X_test_timestamp,\n",
    "#             X_test_volume,\n",
    "#             #X_test_trends,\n",
    "#             X_test_lagged_price\n",
    "#         ],\n",
    "#         [\n",
    "#             Y_test_is_spike_onehot\n",
    "#         ]),\n",
    "    epochs=40,\n",
    "    batch_size=64,\n",
    "    callbacks=[\n",
    "      tensorboard_callback\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2062307fbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "#plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096/4200 [============================>.] - ETA: 0s\n",
      "\n",
      "Accuracy: 78.90%\n"
     ]
    }
   ],
   "source": [
    "score = rnn.evaluate(\n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_test_is_spike_onehot\n",
    "    ])\n",
    "\n",
    "print('\\n')\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if Google Trends actually have any benefit in predicting spikes, I ran one with and without the trend data as input. \n",
    "\n",
    "For \"Is Spike\" cutoff of 0.1, \n",
    "    With trend data, accuracy was 78.90% on test data.\n",
    "    Without trend data, accuracy was 82.93% on test data.\n",
    "    \n",
    "For \"Is Spike\" cutoff of 0.3, \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.94867986,  0.00573033,  0.04558977],\n",
       "       [ 0.87315875,  0.11095729,  0.01588404],\n",
       "       [ 0.96278954,  0.00701143,  0.03019906],\n",
       "       ..., \n",
       "       [ 0.92579889,  0.06169635,  0.01250479],\n",
       "       [ 0.94856799,  0.03694192,  0.01449005],\n",
       "       [ 0.91606241,  0.04909869,  0.03483887]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0          0    -1.0\n",
       "1          0     0.0\n",
       "2          0     0.0\n",
       "3          0     0.0\n",
       "4          0     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = rnn.predict( \n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "display(yhat)\n",
    "\n",
    "inverted_yhat = np.argmax(yhat,axis=1) #returns INDICES of max \n",
    "onehot_to_val_dict = {0: 0, 1: 1, 2:-1 }\n",
    "\n",
    "inverted_yhat_arr = np.asarray(inverted_yhat)\n",
    "predicted = [onehot_to_val_dict[i] for i in inverted_yhat_arr]\n",
    "\n",
    "\n",
    "df_pred_output = pd.DataFrame(predicted, columns=['predicted'])\n",
    "df_pred_output['actual'] = Y_test_is_spike\n",
    "#df_pred_output['index_output'] = inverted_yhat\n",
    "display(df_pred_output.head())\n",
    "\n",
    "# correct = (df_pred_output['actual'].values == df_pred_output['predicted'].values)\n",
    "# accuracy = correct.sum() / correct.size\n",
    "# display(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON# serial \n",
    "model_json = rnn.to_json()\n",
    "with open(\"model_classification.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "rnn.save_weights(\"model_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>523</td>\n",
       "      <td>422</td>\n",
       "      <td>14</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>75</td>\n",
       "      <td>2067</td>\n",
       "      <td>160</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>13</td>\n",
       "      <td>202</td>\n",
       "      <td>724</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>611</td>\n",
       "      <td>2691</td>\n",
       "      <td>898</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   -1     0    1   All\n",
       "Actual                         \n",
       "-1.0       523   422   14   959\n",
       "0.0         75  2067  160  2302\n",
       "1.0         13   202  724   939\n",
       "All        611  2691  898  4200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#print(metrics.confusion_matrix(df_pred_output['actual'].values, df_pred_output['predicted'].values,labels=[0,1,-1]))\n",
    "\n",
    "confusion_matrix = pd.crosstab(df_pred_output['actual'].values, df_pred_output['predicted'].values, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to check what the rnn actually learned \n",
    "# visualize predicted vs actual to get insight into this \n",
    "\n",
    "# try with instead of just 10% biggest changes, maybe with 25% \n",
    "# is it just learning from the previous prices, or is google trends actually helping \n",
    "# -> run rnn without google trends \n",
    "\n",
    "\n",
    "# I have a master_df_v2 now so try that - this one has 0.3 as cutoff for is Spike \n",
    "# Have to eventually get validation data - also get overall newer more data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
