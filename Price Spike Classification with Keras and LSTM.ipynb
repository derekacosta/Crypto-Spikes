{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# features is a list of strings of feature names \n",
    "\n",
    "def build_model(features, data_length):\n",
    "    \n",
    "    inputs_list = [] \n",
    "    for feature_name in features:\n",
    "        inputs_list.append((Input(shape=(data_length,1), name=feature_name)))\n",
    "    \n",
    "    layers = [] \n",
    "    for i, input_name in enumerate(inputs_list): \n",
    "        layers.append(LSTM(64, return_sequences=False)(inputs_list[i]) )\n",
    "        \n",
    "    output = concatenate(layers) \n",
    "    output = Dense(1, activation='softmax', name='IsSpike')(output)\n",
    "    \n",
    "    model = Model(\n",
    "        inputs = inputs_list,\n",
    "        outputs = [output]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model    \n",
    "\n",
    "data_length = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Shoya\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume_BTC</th>\n",
       "      <th>Bitcoin_Adj</th>\n",
       "      <th>Close</th>\n",
       "      <th>Price_lagged</th>\n",
       "      <th>Is Spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.742111</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>0.549540</td>\n",
       "      <td>0.463739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.537603</td>\n",
       "      <td>0.484887</td>\n",
       "      <td>0.496233</td>\n",
       "      <td>0.545460</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.557162</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>0.574526</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.183770</td>\n",
       "      <td>0.443310</td>\n",
       "      <td>0.533819</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.754163</td>\n",
       "      <td>0.431608</td>\n",
       "      <td>0.540560</td>\n",
       "      <td>0.514868</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Volume_BTC  Bitcoin_Adj     Close  Price_lagged  Is Spike\n",
       "10    0.742111     0.422363  0.549540      0.463739       0.0\n",
       "11    0.537603     0.484887  0.496233      0.545460      -1.0\n",
       "12    0.557162     0.407654  0.574526      0.550962       0.0\n",
       "13    0.183770     0.443310  0.533819      0.548729       0.0\n",
       "14    0.754163     0.431608  0.540560      0.514868       0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "master_df = pd.read_csv('C:/Users/Shoya/surf/data/master_df.csv', encoding='latin1')\n",
    "df = master_df[['Timestamp', 'Close', 'Volume_(BTC)', 'Volume_(Currency)', 'Date(UTC)', 'Bitcoin (Adj.Overlap)', \n",
    "               'Close Price % Change', 'Close Price % Change (Abs)', 'Is Spike']]\n",
    "\n",
    "# lag inputs depending on data_length \n",
    "df['Price_lagged'] = df['Close'].shift(data_length)\n",
    "df['Volume_BTC'] = df['Volume_(BTC)'].shift(data_length)\n",
    "df['Bitcoin_Adj'] = df['Bitcoin (Adj.Overlap)'].shift(data_length)\n",
    "\n",
    "df = df.dropna()\n",
    "cols = ['Volume_BTC','Bitcoin_Adj', 'Close', 'Price_lagged']\n",
    "\n",
    "# Stationalize Data by taking log differences\n",
    "data_array = np.diff(np.log(df[cols]), axis=0)\n",
    "\n",
    "# Min-Max Scale \n",
    "\n",
    "scalers = {}\n",
    "datas = [] \n",
    "\n",
    "df_scaled = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(cols)): \n",
    "    scalers[cols[i]] = MinMaxScaler()\n",
    "    #print('data', data_array[:,i])\n",
    "    \n",
    "    col_data = data_array[:,i]\n",
    "    col_data = np.reshape(col_data, (len(col_data), 1))\n",
    "    \n",
    "    data = scalers[cols[i]].fit_transform( col_data )  #:, np.newaxis\n",
    "    #print('scaled', data)\n",
    "    data = np.reshape(data, (1, len(data)))\n",
    "    df_scaled[cols[i]] = data[0]\n",
    "    \n",
    "df_scaled['Is Spike'] = df['Is Spike']\n",
    "df_scaled.dropna(inplace=True)\n",
    "display(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.77679111],\n",
       "        [ 0.4633158 ],\n",
       "        [ 0.72507941],\n",
       "        ..., \n",
       "        [ 0.43692676],\n",
       "        [ 0.7421114 ],\n",
       "        [ 0.53760341]],\n",
       "\n",
       "       [[ 0.55716235],\n",
       "        [ 0.18376964],\n",
       "        [ 0.75416316],\n",
       "        ..., \n",
       "        [ 0.3839469 ],\n",
       "        [ 0.50736037],\n",
       "        [ 0.69401107]],\n",
       "\n",
       "       [[ 0.55575319],\n",
       "        [ 0.37927431],\n",
       "        [ 0.67141699],\n",
       "        ..., \n",
       "        [ 0.6548668 ],\n",
       "        [ 0.62274773],\n",
       "        [ 0.30933732]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.25876546],\n",
       "        [ 0.488586  ],\n",
       "        [ 0.47574397],\n",
       "        ..., \n",
       "        [ 0.76213578],\n",
       "        [ 0.48108754],\n",
       "        [ 0.41414922]],\n",
       "\n",
       "       [[ 0.47271567],\n",
       "        [ 0.70090827],\n",
       "        [ 0.4060511 ],\n",
       "        ..., \n",
       "        [ 0.74667333],\n",
       "        [ 0.39332509],\n",
       "        [ 0.59644994]],\n",
       "\n",
       "       [[ 0.5602949 ],\n",
       "        [ 0.46956629],\n",
       "        [ 0.30546802],\n",
       "        ..., \n",
       "        [ 0.45286573],\n",
       "        [ 0.66948196],\n",
       "        [ 0.63114748]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split and reshape data to feed into RNN\n",
    "\n",
    "# X_timestamp = df_scaled['Timestamp'].values\n",
    "X_volume = df_scaled['Volume_BTC'].values\n",
    "X_trends = df_scaled['Bitcoin_Adj'].values\n",
    "X_lagged_price = df_scaled['Price_lagged'].values\n",
    "\n",
    "Y_is_spike = df_scaled['Is Spike'].values \n",
    "\n",
    "train_size = int(len(X_volume) * 0.85)\n",
    "train_size = int(train_size/data_length) * data_length\n",
    "\n",
    "test_size_index = int(len(X_volume)/data_length)*data_length\n",
    "\n",
    "# X_train_timestamp, X_test_timestamp = X_timestamp[:train_size], X_timestamp[train_size:test_size_index ]\n",
    "X_train_volume, X_test_volume = X_volume[:train_size], X_volume[train_size:test_size_index ]\n",
    "X_train_trends, X_test_trends = X_trends[:train_size], X_trends[train_size:test_size_index ]\n",
    "X_train_lagged_price, X_test_lagged_price = X_lagged_price[:train_size], X_lagged_price[train_size:test_size_index ]\n",
    "\n",
    "Y_train_is_spike, Y_test_is_spike = Y_is_spike[:train_size], Y_is_spike[train_size:test_size_index ]\n",
    "\n",
    "\n",
    "# X.shape is (samples, timesteps, dimension) \n",
    "# timestemps is 15, samples is just however many nobs there are (but it doesn't matter, so it should be None)\n",
    "\n",
    "\n",
    "\n",
    "# X_train_timestamp = np.reshape(X_train_timestamp, (int(X_train_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "X_train_volume = np.reshape(X_train_volume, (int(X_train_volume.shape[0]/data_length),data_length,1) ) \n",
    "X_train_trends = np.reshape(X_train_trends, (int(X_train_trends.shape[0]/data_length),data_length,1) ) \n",
    "X_train_lagged_price = np.reshape(X_train_lagged_price, (int(X_train_lagged_price.shape[0]/data_length), data_length, 1))\n",
    "\n",
    "# X_test_timestamp = np.reshape(X_test_timestamp, (int(X_test_timestamp.shape[0]/data_length),data_length,1) ) \n",
    "X_test_volume = np.reshape(X_test_volume, (int(X_test_volume.shape[0]/data_length),data_length,1) ) \n",
    "X_test_trends = np.reshape(X_test_trends, (int(X_test_trends.shape[0]/data_length),data_length,1) )  \n",
    "X_test_lagged_price = np.reshape(X_test_lagged_price, (int(X_test_lagged_price.shape[0]/data_length),data_length,1))\n",
    "\n",
    "\n",
    "# Don't need the 1 for the third dimension for Y's??\n",
    "\n",
    "\n",
    "Y_train_is_spike = np.reshape(Y_train_is_spike, (int(Y_train_is_spike.shape[0]/data_length),  data_length) ) \n",
    "Y_test_is_spike = np.reshape(Y_test_is_spike, (int(Y_test_is_spike.shape[0]/data_length),  data_length) )\n",
    "\n",
    "\n",
    "\n",
    "# instead of using input 1,2,3,4,5,6,7,8,9,10 to predict output for 11,12,13,14,15,16,17,18,19,20\n",
    "# I want to use input 1,2,3,4,5,6,7,8,9,10 to predict output for 11, then 2,3,4,5,6,7,8,9,10,11 to predict output for 12 \n",
    "\n",
    "# right now I am actually feeding input 1,2,3,4,5,6,7,8,9,10 to predict output for 1,2,3,4,5,6,7,8,9,10. \n",
    "# instead I should at least feed 1,2,3..8,9,10 to predict 11,12,13,14,15,16,17,18,19,20 -> lag everything by data_length! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2386 samples, validate on 421 samples\n",
      "Epoch 1/10\n",
      "2386/2386 [==============================] - 4s - loss: 0.0600 - categorical_accuracy: 0.0373 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 2/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 3/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 4/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 5/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 6/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 7/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 8/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 9/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n",
      "Epoch 10/10\n",
      "2386/2386 [==============================] - 3s - loss: 0.0068 - categorical_accuracy: 0.0348 - val_loss: 0.9188 - val_categorical_accuracy: 0.0475\n"
     ]
    }
   ],
   "source": [
    "features = ['Volume_BTC', 'Bitcoin_Adj', 'Price_lagged']\n",
    "\n",
    "rnn = build_model(features, 10) \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "history = rnn.fit(\n",
    "    [\n",
    "        #X_train_timestamp,\n",
    "        X_train_volume,\n",
    "        X_train_trends,\n",
    "        X_train_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_train_is_spike\n",
    "    ]\n",
    "    ,\n",
    "    validation_data=(\n",
    "        [\n",
    "            #X_test_timestamp,\n",
    "            X_test_volume,\n",
    "            X_test_trends,\n",
    "            X_test_lagged_price\n",
    "        ],\n",
    "        [\n",
    "            Y_test_is_spike\n",
    "        ]),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "      tensorboard_callback\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 0s     \n",
      "Accuracy: 4.75%\n"
     ]
    }
   ],
   "source": [
    "score = rnn.evaluate(\n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    [\n",
    "        Y_test_is_spike\n",
    "    ])\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04118741,  0.04820677,  0.01170081, ..., -0.06489895,\n",
       "        -0.12635459,  0.04566633],\n",
       "       [ 0.04067064,  0.048839  ,  0.01867078, ..., -0.06471471,\n",
       "        -0.11981186,  0.04568062],\n",
       "       [ 0.04209199,  0.04844366,  0.01405586, ..., -0.06447315,\n",
       "        -0.12522832,  0.04572744],\n",
       "       ..., \n",
       "       [ 0.0394179 ,  0.04518746,  0.01890367, ..., -0.06555228,\n",
       "        -0.1281513 ,  0.04599499],\n",
       "       [ 0.0422116 ,  0.04837319,  0.01481877, ..., -0.06414334,\n",
       "        -0.12189236,  0.04572504],\n",
       "       [ 0.04029136,  0.04628353,  0.02012031, ..., -0.06370412,\n",
       "        -0.11830761,  0.04467715]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yhat = rnn.predict( \n",
    "    [\n",
    "        #X_test_timestamp,\n",
    "        X_test_volume,\n",
    "        X_test_trends,\n",
    "        X_test_lagged_price\n",
    "    ],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "display(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to actually categorize output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
